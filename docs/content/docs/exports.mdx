---
title: Export System
description: Comprehensive guide to ProxyWhirl's flexible export system supporting 7+ formats with advanced filtering
icon: fa/FaDownload
---

# Export System

ProxyWhirl provides a powerful and flexible export system that can transform your proxy data into various formats with advanced filtering, sampling, and formatting options. Perfect for integration with other tools, analytics, or data processing pipelines.

## Export Formats

ProxyWhirl supports 12+ export formats across 5 major categories:

### JSON Formats

#### Standard JSON
```json
{
  "metadata": {
    "exported_at": "2024-01-01T12:00:00Z",
    "total_proxies": 150,
    "format": "json"
  },
  "proxies": [
    {
      "host": "192.168.1.100",
      "port": 8080,
      "schemes": ["http", "https"],
      "country_code": "US",
      "anonymity": "elite",
      "success_rate": 0.95,
      "response_time": 0.85
    }
  ]
}
```

**Available JSON Variants:**
- `JSON` - Standard JSON format
- `JSON_PRETTY` - Pretty-printed with indentation
- `JSON_COMPACT` - Compact single-line format

### CSV Formats

#### Standard CSV
```csv
host,port,schemes,country_code,anonymity,success_rate,response_time,last_checked
192.168.1.100,8080,"http,https",US,elite,0.95,0.85,2024-01-01T12:00:00Z
10.0.0.50,3128,"http",DE,anonymous,0.87,1.24,2024-01-01T11:55:00Z
172.16.0.25,1080,"socks5",JP,elite,0.92,2.15,2024-01-01T11:58:00Z
```

**Available CSV Variants:**
- `CSV` - Standard CSV with headers
- `CSV_HEADERS` - CSV with explicit headers
- `CSV_NO_HEADERS` - Data only, no headers

### Text Formats

#### Host:Port Format
```text
192.168.1.100:8080
10.0.0.50:3128
172.16.0.25:1080
```

#### URI Format
```text
http://192.168.1.100:8080
https://10.0.0.50:3128
socks5://172.16.0.25:1080
```

#### Detailed Text Format
```text
US    192.168.1.100:8080    HTTP/HTTPS    Elite      95% success    0.85s
DE    10.0.0.50:3128        HTTP          Anonymous  87% success    1.24s
JP    172.16.0.25:1080      SOCKS5        Elite      92% success    2.15s
```

**Available Text Variants:**
- `TXT_HOSTPORT` - Simple host:port format
- `TXT_URI` - Full URI format with schemes
- `TXT_SIMPLE` - One proxy per line, minimal info
- `TXT_DETAILED` - Detailed tabular format

### XML Format

```xml
<?xml version="1.0" encoding="UTF-8"?>
<proxies total="150" exported_at="2024-01-01T12:00:00Z">
  <proxy>
    <host>192.168.1.100</host>
    <port>8080</port>
    <schemes>
      <scheme>http</scheme>
      <scheme>https</scheme>
    </schemes>
    <country_code>US</country_code>
    <anonymity>elite</anonymity>
    <success_rate>0.95</success_rate>
    <response_time>0.85</response_time>
  </proxy>
</proxies>
```

### YAML Format

```yaml
metadata:
  exported_at: "2024-01-01T12:00:00Z"
  total_proxies: 150
  format: yaml

proxies:
  - host: 192.168.1.100
    port: 8080
    schemes: [http, https]
    country_code: US
    anonymity: elite
    success_rate: 0.95
    response_time: 0.85
```

### SQL Format

```sql
-- Proxy data export generated by ProxyWhirl
-- Generated: 2024-01-01T12:00:00Z

CREATE TABLE IF NOT EXISTS proxies (
    host TEXT NOT NULL,
    port INTEGER NOT NULL,
    schemes TEXT,
    country_code TEXT,
    anonymity TEXT,
    success_rate REAL,
    response_time REAL,
    last_checked TIMESTAMP
);

INSERT INTO proxies VALUES ('192.168.1.100', 8080, 'http,https', 'US', 'elite', 0.95, 0.85, '2024-01-01T12:00:00Z');
INSERT INTO proxies VALUES ('10.0.0.50', 3128, 'http', 'DE', 'anonymous', 0.87, 1.24, '2024-01-01T11:55:00Z');
```

### PAC (Proxy Auto-Configuration) Format

```javascript
function FindProxyForURL(url, host) {
    // ProxyWhirl PAC file generated 2024-01-01T12:00:00Z
    
    var proxies = [
        "PROXY 192.168.1.100:8080",
        "PROXY 10.0.0.50:3128", 
        "PROXY 172.16.0.25:1080"
    ];
    
    // Use random proxy for load balancing
    var proxy = proxies[Math.floor(Math.random() * proxies.length)];
    return proxy + "; DIRECT";
}
```

## Basic Usage

### Simple Export

```python
import asyncio
from proxywhirl import ProxyWhirl
from proxywhirl.exporter import ProxyExporter, ExportFormat

async def basic_export():
    # Get proxies
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    # Initialize exporter
    exporter = ProxyExporter()
    
    # Export to different formats
    formats_to_try = [
        ExportFormat.JSON_PRETTY,
        ExportFormat.CSV,
        ExportFormat.TXT_HOSTPORT,
        ExportFormat.PAC
    ]
    
    for format_type in formats_to_try:
        try:
            result = await exporter.export_async(
                proxies=proxies,
                format=format_type,
                output_path=f"proxies.{format_type.lower()}"
            )
            print(f"‚úÖ Exported to {format_type}: {len(result)} characters")
        except Exception as e:
            print(f"‚ùå Export failed for {format_type}: {e}")

asyncio.run(basic_export())
```

### Export to Files

```python
from pathlib import Path
from proxywhirl.exporter import ProxyExporter, ExportConfig, ExportFormat

async def export_to_files():
    # Get your proxies
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = ProxyExporter()
    
    # Define export configurations
    export_configs = [
        ExportConfig(
            format=ExportFormat.JSON_PRETTY,
            output_file="all_proxies.json"
        ),
        ExportConfig(
            format=ExportFormat.CSV_HEADERS,
            output_file="proxy_data.csv"
        ),
        ExportConfig(
            format=ExportFormat.TXT_URI,
            output_file="proxy_list.txt"
        ),
        ExportConfig(
            format=ExportFormat.PAC,
            output_file="proxy.pac"
        )
    ]
    
    # Export to files
    for config in export_configs:
        try:
            await exporter.export_to_file_async(proxies, config)
            file_size = Path(config.output_file).stat().st_size
            print(f"‚úÖ Exported {config.format} to {config.output_file} ({file_size} bytes)")
        except Exception as e:
            print(f"‚ùå Failed to export {config.format}: {e}")

asyncio.run(export_to_files())
```

## Advanced Filtering

### Geographic Filtering

```python
from proxywhirl.exporter import ProxyExporter, ExportConfig, ProxyFilter, ExportFormat

async def geographic_filtering():
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = ProxyExporter()
    
    # US and Canadian proxies only
    us_ca_config = ExportConfig(
        format=ExportFormat.JSON_PRETTY,
        filters=ProxyFilter(
            countries=["US", "CA"],
            min_success_rate=0.8
        ),
        output_file="north_america_proxies.json"
    )
    
    # European proxies, exclude certain countries
    eu_config = ExportConfig(
        format=ExportFormat.CSV,
        filters=ProxyFilter(
            countries=["DE", "FR", "UK", "NL", "IT"],
            exclude_countries=["RU"],
            min_response_time=0.5,
            max_response_time=2.0
        ),
        output_file="europe_proxies.csv"
    )
    
    # Asian proxies with high performance
    asia_config = ExportConfig(
        format=ExportFormat.TXT_DETAILED,
        filters=ProxyFilter(
            countries=["JP", "KR", "SG", "HK"],
            min_success_rate=0.9,
            max_response_time=1.0,
            anonymity_levels=["elite"]
        ),
        output_file="asia_premium.txt"
    )
    
    configs = [us_ca_config, eu_config, asia_config]
    
    for config in configs:
        result_count = await exporter.export_to_file_async(proxies, config)
        print(f"üìç {config.output_file}: {result_count} proxies exported")

asyncio.run(geographic_filtering())
```

### Performance-Based Filtering

```python
from datetime import datetime, timedelta
from proxywhirl.exporter import ProxyFilter, ExportConfig, ExportFormat

async def performance_filtering():
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = ProxyExporter()
    
    # High-performance proxies
    premium_config = ExportConfig(
        format=ExportFormat.JSON_PRETTY,
        filters=ProxyFilter(
            min_success_rate=0.95,
            max_response_time=0.8,
            min_quality_score=0.9,
            anonymity_levels=["elite"],
            healthy_only=True
        ),
        output_file="premium_proxies.json"
    )
    
    # Recently validated proxies
    recent_time = datetime.now() - timedelta(hours=1)
    fresh_config = ExportConfig(
        format=ExportFormat.CSV,
        filters=ProxyFilter(
            checked_after=recent_time,
            min_success_rate=0.7,
            max_consecutive_failures=2
        ),
        output_file="fresh_proxies.csv"
    )
    
    # Fast HTTP proxies for web scraping
    web_scraping_config = ExportConfig(
        format=ExportFormat.TXT_URI,
        filters=ProxyFilter(
            schemes=["http", "https"],
            max_response_time=1.5,
            min_success_rate=0.8,
            exclude_countries=["CN", "RU"]  # Exclude if needed
        ),
        output_file="web_scraping_proxies.txt"
    )
    
    configs = [premium_config, fresh_config, web_scraping_config]
    
    for config in configs:
        count = await exporter.export_to_file_async(proxies, config)
        print(f"‚ö° {config.output_file}: {count} high-performance proxies")

asyncio.run(performance_filtering())
```

### Source and Technical Filtering

```python
from proxywhirl.exporter import ProxyFilter, ExportConfig, ExportFormat

async def technical_filtering():
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = ProxyExporter()
    
    # SOCKS5 proxies only
    socks_config = ExportConfig(
        format=ExportFormat.TXT_URI,
        filters=ProxyFilter(
            schemes=["socks5"],
            min_success_rate=0.8
        ),
        output_file="socks5_proxies.txt"
    )
    
    # Specific port ranges (common web ports)
    web_ports_config = ExportConfig(
        format=ExportFormat.CSV,
        filters=ProxyFilter(
            ports=[80, 8080, 3128, 8000, 8888],
            schemes=["http", "https"]
        ),
        output_file="web_port_proxies.csv"
    )
    
    # From specific sources
    trusted_sources_config = ExportConfig(
        format=ExportFormat.JSON,
        filters=ProxyFilter(
            sources=["the-speedx-http", "clarketm-http"],
            exclude_sources=["untrusted-loader"],
            min_success_rate=0.85
        ),
        output_file="trusted_source_proxies.json"
    )
    
    configs = [socks_config, web_ports_config, trusted_sources_config]
    
    for config in configs:
        count = await exporter.export_to_file_async(proxies, config)
        print(f"üîß {config.output_file}: {count} technically filtered proxies")

asyncio.run(technical_filtering())
```

## Volume Controls and Sampling

### Sampling Methods

```python
from proxywhirl.exporter import (
    ExportConfig, VolumeControl, SamplingMethod, 
    SortField, SortOrder, ExportFormat
)

async def sampling_examples():
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = ProxyExporter()
    
    # Top 100 highest quality proxies
    top_quality_config = ExportConfig(
        format=ExportFormat.JSON_PRETTY,
        volume=VolumeControl(
            limit=100,
            sampling_method=SamplingMethod.TOP_QUALITY
        ),
        output_file="top_100_quality.json"
    )
    
    # Top 50 fastest proxies
    fastest_config = ExportConfig(
        format=ExportFormat.CSV,
        volume=VolumeControl(
            limit=50,
            sampling_method=SamplingMethod.TOP_SPEED,
            sort_field=SortField.RESPONSE_TIME,
            sort_order=SortOrder.ASC
        ),
        output_file="fastest_50.csv"
    )
    
    # Random sample of 200 proxies
    random_config = ExportConfig(
        format=ExportFormat.TXT_HOSTPORT,
        volume=VolumeControl(
            limit=200,
            sampling_method=SamplingMethod.RANDOM
        ),
        output_file="random_200.txt"
    )
    
    # Balanced across all sources (10 from each)
    balanced_config = ExportConfig(
        format=ExportFormat.YAML,
        volume=VolumeControl(
            sampling_method=SamplingMethod.BALANCED,
            balance_per_group=10,
            balance_field="source"
        ),
        output_file="balanced_sources.yaml"
    )
    
    configs = [top_quality_config, fastest_config, random_config, balanced_config]
    
    for config in configs:
        count = await exporter.export_to_file_async(proxies, config)
        print(f"üìä {config.output_file}: {count} sampled proxies")

asyncio.run(sampling_examples())
```

### Pagination and Distribution

```python
from proxywhirl.exporter import VolumeControl, SamplingMethod

async def pagination_examples():
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = ProxyExporter()
    
    # Export in batches of 100
    batch_size = 100
    total_proxies = len(proxies)
    batch_count = (total_proxies + batch_size - 1) // batch_size
    
    print(f"üì¶ Exporting {total_proxies} proxies in {batch_count} batches of {batch_size}")
    
    for batch_num in range(batch_count):
        offset = batch_num * batch_size
        
        batch_config = ExportConfig(
            format=ExportFormat.JSON,
            volume=VolumeControl(
                offset=offset,
                limit=batch_size,
                sampling_method=SamplingMethod.FIRST
            ),
            output_file=f"batch_{batch_num + 1:03d}.json"
        )
        
        count = await exporter.export_to_file_async(proxies, batch_config)
        print(f"  ‚úÖ Batch {batch_num + 1}: {count} proxies")
    
    print("üì¶ All batches exported successfully!")

asyncio.run(pagination_examples())
```

## Custom Export Formats

### Creating Custom Formats

```python
from proxywhirl.exporter import ProxyExporter
from proxywhirl.models import Proxy
from typing import List

class CustomProxyExporter(ProxyExporter):
    """Extended exporter with custom formats."""
    
    def __init__(self):
        super().__init__()
        # Add custom format handlers
        self._format_handlers['NGINX_UPSTREAM'] = self._format_nginx_upstream
        self._format_handlers['SQUID_ACL'] = self._format_squid_acl
        self._format_handlers['HAPROXY_BACKEND'] = self._format_haproxy_backend
    
    def _format_nginx_upstream(self, proxies: List[Proxy], config) -> str:
        """Format proxies for NGINX upstream configuration."""
        lines = ["upstream proxy_backend {"]
        
        for proxy in proxies:
            weight = int(proxy.success_rate * 10) if proxy.success_rate else 1
            lines.append(f"    server {proxy.host}:{proxy.port} weight={weight};")
        
        lines.append("}")
        return "\n".join(lines)
    
    def _format_squid_acl(self, proxies: List[Proxy], config) -> str:
        """Format proxies for Squid ACL configuration."""
        lines = ["# Squid proxy ACL configuration"]
        lines.append("acl proxy_servers dstdomain \\")
        
        for i, proxy in enumerate(proxies):
            terminator = " \\" if i < len(proxies) - 1 else ""
            lines.append(f"    {proxy.host}{terminator}")
        
        lines.append("")
        lines.append("cache_peer_access proxy_servers allow all")
        return "\n".join(lines)
    
    def _format_haproxy_backend(self, proxies: List[Proxy], config) -> str:
        """Format proxies for HAProxy backend configuration."""
        lines = ["backend proxy_backend"]
        lines.append("    mode http")
        lines.append("    balance roundrobin")
        
        for i, proxy in enumerate(proxies):
            server_name = f"proxy_{i+1:03d}"
            check = "check" if proxy.success_rate and proxy.success_rate > 0.8 else "check backup"
            lines.append(f"    server {server_name} {proxy.host}:{proxy.port} {check}")
        
        return "\n".join(lines)

# Usage example
async def custom_format_example():
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = CustomProxyExporter()
    
    # Export in custom formats
    custom_formats = [
        ('NGINX_UPSTREAM', 'nginx_upstream.conf'),
        ('SQUID_ACL', 'squid_acl.conf'),
        ('HAPROXY_BACKEND', 'haproxy_backend.conf')
    ]
    
    for format_name, filename in custom_formats:
        config = ExportConfig(
            format=format_name,
            filters=ProxyFilter(min_success_rate=0.8),
            output_file=filename
        )
        
        count = await exporter.export_to_file_async(proxies, config)
        print(f"üîß {filename}: {count} proxies in {format_name} format")

asyncio.run(custom_format_example())
```

### Template-based Exports

```python
from string import Template
from proxywhirl.exporter import ProxyExporter
from proxywhirl.models import Proxy

class TemplateExporter(ProxyExporter):
    """Template-based proxy exporter for custom formats."""
    
    def export_with_template(self, proxies: List[Proxy], template_str: str, **kwargs) -> str:
        """Export proxies using a string template."""
        template = Template(template_str)
        
        proxy_lines = []
        for proxy in proxies:
            proxy_data = {
                'host': proxy.host,
                'port': proxy.port,
                'country': proxy.country_code or 'unknown',
                'schemes': ','.join(proxy.schemes),
                'success_rate': f"{proxy.success_rate:.1%}" if proxy.success_rate else "unknown",
                'response_time': f"{proxy.response_time:.2f}s" if proxy.response_time else "unknown"
            }
            proxy_data.update(kwargs)  # Add any additional template variables
            
            try:
                proxy_lines.append(template.substitute(proxy_data))
            except KeyError as e:
                print(f"Template variable missing: {e}")
                continue
        
        return '\n'.join(proxy_lines)

# Usage examples
async def template_export_examples():
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()[:10]  # First 10 proxies
    
    exporter = TemplateExporter()
    
    # Docker Compose template
    docker_template = """  proxy_$host:
    image: nginx:alpine
    environment:
      - PROXY_HOST=$host
      - PROXY_PORT=$port
    labels:
      - "country=$country"
      - "success_rate=$success_rate" """
    
    docker_result = exporter.export_with_template(
        proxies, 
        docker_template,
        service_prefix="proxywhirl"
    )
    
    with open("docker-compose-proxies.yml", "w") as f:
        f.write("version: '3.8'\nservices:\n")
        f.write(docker_result)
    
    # Kubernetes ConfigMap template
    k8s_template = """  $host: |
    server $host:$port;
    # Country: $country, Success: $success_rate, Response: $response_time"""
    
    k8s_result = exporter.export_with_template(proxies, k8s_template)
    
    with open("proxy-configmap.yaml", "w") as f:
        f.write("apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: proxy-config\ndata:\n")
        f.write(k8s_result)
    
    # Custom log format template
    log_template = "[$country] $host:$port - Success: $success_rate, Speed: $response_time"
    log_result = exporter.export_with_template(proxies, log_template)
    
    with open("proxy-report.log", "w") as f:
        f.write(log_result)
    
    print("‚úÖ Template exports completed:")
    print("  üì¶ docker-compose-proxies.yml")
    print("  ‚ò∏Ô∏è  proxy-configmap.yaml")
    print("  üìÑ proxy-report.log")

asyncio.run(template_export_examples())
```

## Integration Examples

### Web Applications

```python
from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import PlainTextResponse, StreamingResponse
from proxywhirl import ProxyWhirl
from proxywhirl.exporter import ProxyExporter, ExportConfig, ProxyFilter, ExportFormat
import io

app = FastAPI()
proxy_whirl = ProxyWhirl()
exporter = ProxyExporter()

@app.on_event("startup")
async def startup():
    await proxy_whirl.fetch_proxies()

@app.get("/api/proxies/export")
async def export_proxies(
    format: ExportFormat = Query(ExportFormat.JSON),
    country: str = Query(None),
    min_success_rate: float = Query(0.0),
    limit: int = Query(None)
):
    """Export proxies via REST API."""
    try:
        proxies = proxy_whirl.list_proxies()
        
        # Build filter
        filters = ProxyFilter(
            min_success_rate=min_success_rate if min_success_rate > 0 else None
        )
        if country:
            filters.countries = [country.upper()]
        
        # Build config
        config = ExportConfig(
            format=format,
            filters=filters,
            volume=VolumeControl(limit=limit) if limit else None
        )
        
        # Export data
        result = await exporter.export_async(proxies, config)
        
        # Return appropriate response
        media_type = {
            ExportFormat.JSON: "application/json",
            ExportFormat.CSV: "text/csv",
            ExportFormat.XML: "application/xml",
            ExportFormat.YAML: "application/yaml",
        }.get(format, "text/plain")
        
        return PlainTextResponse(result, media_type=media_type)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/proxies/download")
async def download_proxies(
    format: ExportFormat = Query(ExportFormat.TXT_HOSTPORT),
    country: str = Query(None)
):
    """Download proxies as file."""
    try:
        proxies = proxy_whirl.list_proxies()
        
        filters = ProxyFilter()
        if country:
            filters.countries = [country.upper()]
        
        config = ExportConfig(format=format, filters=filters)
        result = await exporter.export_async(proxies, config)
        
        # Create file response
        buffer = io.BytesIO(result.encode('utf-8'))
        filename = f"proxies_{country or 'all'}.{format.lower()}"
        
        return StreamingResponse(
            io.BytesIO(result.encode('utf-8')),
            media_type="application/octet-stream",
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### Data Pipeline Integration

```python
import pandas as pd
from proxywhirl import ProxyWhirl
from proxywhirl.exporter import ProxyExporter, ExportConfig, ExportFormat

class ProxyDataPipeline:
    """Data pipeline for proxy processing and export."""
    
    def __init__(self):
        self.proxy_whirl = ProxyWhirl(
            cache_type="sqlite",
            cache_path="pipeline_proxies.db"
        )
        self.exporter = ProxyExporter()
    
    async def refresh_data(self):
        """Refresh proxy data from all sources."""
        count = await self.proxy_whirl.fetch_proxies(validate=True)
        print(f"üîÑ Refreshed {count} validated proxies")
        return count
    
    async def export_analytics_data(self):
        """Export data for analytics platforms."""
        proxies = self.proxy_whirl.list_proxies()
        
        # Export for different analytics tools
        analytics_exports = [
            # Tableau/Power BI
            ExportConfig(
                format=ExportFormat.CSV_HEADERS,
                output_file="analytics/proxies_full.csv"
            ),
            
            # Python/Pandas analysis
            ExportConfig(
                format=ExportFormat.JSON,
                output_file="analytics/proxies_data.json"
            ),
            
            # R analysis
            ExportConfig(
                format=ExportFormat.CSV,
                filters=ProxyFilter(healthy_only=True),
                output_file="analytics/healthy_proxies.csv"
            )
        ]
        
        for config in analytics_exports:
            count = await self.exporter.export_to_file_async(proxies, config)
            print(f"üìä Analytics export {config.output_file}: {count} records")
    
    async def export_by_region(self):
        """Export proxies grouped by geographic regions."""
        proxies = self.proxy_whirl.list_proxies()
        
        regions = {
            'north_america': ['US', 'CA', 'MX'],
            'europe': ['DE', 'FR', 'UK', 'NL', 'IT', 'ES'],
            'asia_pacific': ['JP', 'KR', 'SG', 'HK', 'AU'],
            'others': None  # Will be populated with remaining countries
        }
        
        # Get all unique countries first
        all_countries = {p.country_code for p in proxies if p.country_code}
        covered_countries = set()
        for region_countries in regions.values():
            if region_countries:
                covered_countries.update(region_countries)
        
        # Update 'others' with remaining countries
        regions['others'] = list(all_countries - covered_countries)
        
        for region, countries in regions.items():
            if not countries:
                continue
                
            config = ExportConfig(
                format=ExportFormat.JSON_PRETTY,
                filters=ProxyFilter(
                    countries=countries,
                    min_success_rate=0.7
                ),
                output_file=f"regions/{region}_proxies.json"
            )
            
            count = await self.exporter.export_to_file_async(proxies, config)
            print(f"üåç {region}: {count} proxies exported")
    
    async def create_summary_report(self):
        """Create summary report with statistics."""
        proxies = self.proxy_whirl.list_proxies()
        
        # Calculate statistics
        total_count = len(proxies)
        healthy_count = sum(1 for p in proxies if p.success_rate and p.success_rate > 0.8)
        avg_response = sum(p.response_time for p in proxies if p.response_time) / len([p for p in proxies if p.response_time])
        
        country_dist = {}
        for proxy in proxies:
            if proxy.country_code:
                country_dist[proxy.country_code] = country_dist.get(proxy.country_code, 0) + 1
        
        # Generate report
        report = f"""# Proxy Summary Report
Generated: {datetime.now().isoformat()}

## Statistics
- Total Proxies: {total_count:,}
- Healthy Proxies: {healthy_count:,} ({healthy_count/total_count:.1%})
- Average Response Time: {avg_response:.2f}s

## Top Countries
"""
        for country, count in sorted(country_dist.items(), key=lambda x: x[1], reverse=True)[:10]:
            percentage = (count / total_count) * 100
            report += f"- {country}: {count:,} ({percentage:.1f}%)\n"
        
        with open("reports/proxy_summary.md", "w") as f:
            f.write(report)
        
        print("üìä Summary report generated: reports/proxy_summary.md")

# Usage
async def run_pipeline():
    pipeline = ProxyDataPipeline()
    
    # Refresh data
    await pipeline.refresh_data()
    
    # Run all exports
    await pipeline.export_analytics_data()
    await pipeline.export_by_region()
    await pipeline.create_summary_report()
    
    print("‚úÖ Data pipeline completed successfully!")

asyncio.run(run_pipeline())
```

## Performance and Optimization

### Async Export for Large Datasets

```python
import asyncio
from proxywhirl.exporter import ProxyExporter, ExportConfig, ExportFormat

async def optimized_large_export():
    """Optimized export for large proxy datasets."""
    proxy_whirl = ProxyWhirl()
    await proxy_whirl.fetch_proxies()
    proxies = proxy_whirl.list_proxies()
    
    exporter = ProxyExporter()
    
    # Process in chunks for memory efficiency
    chunk_size = 1000
    total_proxies = len(proxies)
    
    print(f"üì¶ Processing {total_proxies} proxies in chunks of {chunk_size}")
    
    all_exports = []
    for i in range(0, total_proxies, chunk_size):
        chunk = proxies[i:i + chunk_size]
        
        # Create multiple export tasks for this chunk
        tasks = []
        for format_type in [ExportFormat.JSON, ExportFormat.CSV, ExportFormat.TXT_HOSTPORT]:
            config = ExportConfig(
                format=format_type,
                output_file=f"chunks/chunk_{i//chunk_size + 1}_{format_type.lower()}.{format_type.lower()}"
            )
            tasks.append(exporter.export_to_file_async(chunk, config))
        
        # Process chunk exports concurrently
        results = await asyncio.gather(*tasks, return_exceptions=True)
        all_exports.extend(results)
        
        print(f"  ‚úÖ Processed chunk {i//chunk_size + 1}/{(total_proxies + chunk_size - 1)//chunk_size}")
    
    successful_exports = [r for r in all_exports if not isinstance(r, Exception)]
    failed_exports = [r for r in all_exports if isinstance(r, Exception)]
    
    print(f"üìä Export Results:")
    print(f"  ‚úÖ Successful: {len(successful_exports)}")
    print(f"  ‚ùå Failed: {len(failed_exports)}")

asyncio.run(optimized_large_export())
```

### Memory-Efficient Streaming Export

```python
from typing import AsyncGenerator
from proxywhirl.exporter import ProxyExporter
from proxywhirl.models import Proxy

class StreamingExporter(ProxyExporter):
    """Memory-efficient streaming exporter for large datasets."""
    
    async def export_stream(
        self, 
        proxies: AsyncGenerator[Proxy, None], 
        format: ExportFormat
    ) -> AsyncGenerator[str, None]:
        """Export proxies as a stream to minimize memory usage."""
        
        # Yield header based on format
        if format == ExportFormat.JSON:
            yield '{"proxies": ['
            first = True
        elif format == ExportFormat.CSV_HEADERS:
            yield "host,port,schemes,country_code,anonymity,success_rate,response_time\n"
        elif format == ExportFormat.XML:
            yield '<?xml version="1.0" encoding="UTF-8"?>\n<proxies>\n'
        
        # Stream proxy data
        async for proxy in proxies:
            if format == ExportFormat.JSON:
                if not first:
                    yield ","
                yield json.dumps(proxy.dict())
                first = False
            elif format in [ExportFormat.CSV, ExportFormat.CSV_HEADERS]:
                yield f"{proxy.host},{proxy.port},{','.join(proxy.schemes)},{proxy.country_code or ''},{proxy.anonymity},{proxy.success_rate or 0},{proxy.response_time or 0}\n"
            elif format == ExportFormat.TXT_HOSTPORT:
                yield f"{proxy.host}:{proxy.port}\n"
            elif format == ExportFormat.XML:
                yield f"  <proxy><host>{proxy.host}</host><port>{proxy.port}</port></proxy>\n"
        
        # Yield footer based on format
        if format == ExportFormat.JSON:
            yield ']}'
        elif format == ExportFormat.XML:
            yield '</proxies>'

# Usage example
async def streaming_export_example():
    """Example of memory-efficient streaming export."""
    
    async def proxy_generator():
        """Generate proxies from database/source without loading all into memory."""
        proxy_whirl = ProxyWhirl(cache_type="sqlite", cache_path="large_db.db")
        
        # This would typically fetch from database in batches
        all_proxies = proxy_whirl.list_proxies()
        for proxy in all_proxies:
            yield proxy
    
    exporter = StreamingExporter()
    
    # Stream to file
    with open("streamed_export.json", "w") as f:
        async for chunk in exporter.export_stream(proxy_generator(), ExportFormat.JSON):
            f.write(chunk)
    
    print("‚úÖ Streaming export completed with minimal memory usage")

asyncio.run(streaming_export_example())
```

## Best Practices

### 1. Choose the Right Format

```python
# Guidelines for format selection:

# JSON - Best for:
# - API responses
# - Data interchange
# - Preserving full proxy metadata
formats_for_apis = [ExportFormat.JSON, ExportFormat.JSON_COMPACT]

# CSV - Best for:
# - Spreadsheet analysis
# - Data science workflows
# - Database imports
formats_for_analysis = [ExportFormat.CSV, ExportFormat.CSV_HEADERS]

# TXT - Best for:
# - Simple proxy lists
# - Integration with proxy tools
# - Manual configuration
formats_for_tools = [ExportFormat.TXT_HOSTPORT, ExportFormat.TXT_URI]

# PAC - Best for:
# - Browser proxy configuration
# - Network administration
# - Automatic proxy selection
formats_for_browsers = [ExportFormat.PAC]
```

### 2. Optimize Filtering

```python
# Efficient filtering practices:

# Pre-filter at source when possible
efficient_filter = ProxyFilter(
    healthy_only=True,  # Reduces dataset size early
    min_success_rate=0.8,  # Quality threshold
    max_response_time=2.0  # Performance threshold
)

# Combine geographic and performance filters
combined_filter = ProxyFilter(
    countries=["US", "CA", "DE"],  # Specific regions
    min_success_rate=0.9,
    anonymity_levels=["elite"],
    schemes=["http", "https"]  # Specific protocols only
)
```

### 3. Handle Large Datasets

```python
# For large datasets, use volume controls:

large_dataset_config = ExportConfig(
    format=ExportFormat.JSON,
    volume=VolumeControl(
        limit=10000,  # Limit size
        sampling_method=SamplingMethod.TOP_QUALITY,  # Best proxies first
        offset=0  # For pagination
    ),
    filters=ProxyFilter(healthy_only=True)  # Pre-filter
)
```

### 4. Error Handling

```python
async def robust_export():
    """Robust export with comprehensive error handling."""
    
    try:
        proxy_whirl = ProxyWhirl()
        await proxy_whirl.fetch_proxies()
        proxies = proxy_whirl.list_proxies()
        
        if not proxies:
            print("‚ö†Ô∏è  No proxies available for export")
            return
        
        exporter = ProxyExporter()
        
        config = ExportConfig(
            format=ExportFormat.JSON_PRETTY,
            output_file="export_output.json",
            filters=ProxyFilter(min_success_rate=0.8)
        )
        
        count = await exporter.export_to_file_async(proxies, config)
        
        if count == 0:
            print("‚ö†Ô∏è  No proxies matched the export criteria")
        else:
            print(f"‚úÖ Successfully exported {count} proxies")
        
    except ProxyExportError as e:
        print(f"‚ùå Export error: {e}")
        # Handle export-specific errors
        
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        # Handle unexpected errors

asyncio.run(robust_export())
```

### 5. Automation and Scheduling

```python
import schedule
import time
from datetime import datetime

def automated_export_job():
    """Automated export job for scheduling."""
    
    async def export_task():
        proxy_whirl = ProxyWhirl()
        await proxy_whirl.fetch_proxies(validate=True)
        proxies = proxy_whirl.list_proxies()
        
        exporter = ProxyExporter()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Daily export with timestamp
        config = ExportConfig(
            format=ExportFormat.JSON_PRETTY,
            filters=ProxyFilter(healthy_only=True),
            output_file=f"daily_exports/proxies_{timestamp}.json"
        )
        
        count = await exporter.export_to_file_async(proxies, config)
        print(f"üìÖ Daily export completed: {count} proxies")
    
    # Run the async task
    asyncio.run(export_task())

# Schedule daily exports
schedule.every().day.at("02:00").do(automated_export_job)

# Keep the scheduler running
# while True:
#     schedule.run_pending()
#     time.sleep(60)
```